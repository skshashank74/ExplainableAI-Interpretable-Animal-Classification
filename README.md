# ExplainableAI-Interpretable-Animal-Classification

Deep Learning models have shown great performance in complex classification tasks, but are inherently uninterpretable. We created a convolutional neural network as our classifier and analysed how it generates features for the different classes. We further delve into attention maps of the last few layers of CNN models and analyse various class discriminative visualization methodologies - Grad-CAM, Guided Backpropagation and Guided Grad-CAM for explaining the model.
